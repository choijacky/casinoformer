{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "962d3500-488c-46ff-bd4d-998876a3fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from datasets import load_dataset, Dataset # huggingface dZatasets\n",
    "import re\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f909-25bf-4713-a0f1-b9a4f4d7893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(example):\n",
    "    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n",
    "    ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n",
    "    # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n",
    "    out = {'ids': ids, 'len': len(ids)}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1e2cd53-d75f-4641-8572-c4ca5b9e17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2(example):\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5be1b6ad-859b-4fb5-a61f-152e45aab76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Can I become a top tier cellist without studying at a music school?\\n\\nThe only thing you need to do before applying for a cello degree is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39a0c36d-3bf8-43c4-aedf-45265bb5ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.split(r'(\\s)', query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "358084aa-bce0-4e26-a508-d50cccbc4683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a792f0f3-8cf9-4777-b1f7-8b9140ddde28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'become',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'top',\n",
       " ' ',\n",
       " 'tier',\n",
       " ' ',\n",
       " 'cellist',\n",
       " ' ',\n",
       " 'without',\n",
       " ' ',\n",
       " 'studying',\n",
       " ' ',\n",
       " 'at',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'music',\n",
       " ' ',\n",
       " 'school?',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'The',\n",
       " ' ',\n",
       " 'only',\n",
       " ' ',\n",
       " 'thing',\n",
       " ' ',\n",
       " 'you',\n",
       " ' ',\n",
       " 'need',\n",
       " ' ',\n",
       " 'to',\n",
       " ' ',\n",
       " 'do',\n",
       " ' ',\n",
       " 'before',\n",
       " ' ',\n",
       " 'applying',\n",
       " ' ',\n",
       " 'for',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'cello',\n",
       " ' ',\n",
       " 'degree',\n",
       " ' ',\n",
       " 'is']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1c5f6b5-7eef-4598-885d-f0dc9014ae6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m split_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tokenize the dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m split_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m      4\u001b[0m     process2,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#remove_columns=['text'],\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizing the splits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/datasets/arrow_dataset.py:949\u001b[0m, in \u001b[0;36mDataset.from_list\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03mConvert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    [`Dataset`]\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m mapping \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(mapping, features, info, split)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/datasets/arrow_dataset.py:949\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03mConvert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    [`Dataset`]\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {k: \u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mapping[\u001b[38;5;241m0\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(mapping, features, info, split)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/datasets/arrow_dataset.py:949\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03mConvert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    [`Dataset`]\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {k: [\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(k) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m mapping] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mapping[\u001b[38;5;241m0\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(mapping, features, info, split)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "split_dataset = Dataset.from_list(res)\n",
    "# tokenize the dataset\n",
    "tokenized = split_dataset.map(\n",
    "    process2,\n",
    "    #remove_columns=['text'],\n",
    "    desc=\"tokenizing the splits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd5ffec3-6ebe-4ece-b392-671c9b880717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ids', 'len'],\n",
       "    num_rows: 136\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8715c984-fd02-4e82-8dd2-a0d00757c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['ids', 'len'],\n",
      "    num_rows: 136\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcbca8cd-313d-4697-a301-1e6294792af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0 {'ids': [34, 50256], 'len': 2}\n",
      "a 1 {'ids': [64, 50256], 'len': 2}\n",
      "n 2 {'ids': [77, 50256], 'len': 2}\n",
      "  3 {'ids': [220, 50256], 'len': 2}\n",
      "I 4 {'ids': [40, 50256], 'len': 2}\n",
      "  5 {'ids': [220, 50256], 'len': 2}\n",
      "b 6 {'ids': [65, 50256], 'len': 2}\n",
      "e 7 {'ids': [68, 50256], 'len': 2}\n",
      "c 8 {'ids': [66, 50256], 'len': 2}\n",
      "o 9 {'ids': [78, 50256], 'len': 2}\n",
      "m 10 {'ids': [76, 50256], 'len': 2}\n",
      "e 11 {'ids': [68, 50256], 'len': 2}\n",
      "  12 {'ids': [220, 50256], 'len': 2}\n",
      "a 13 {'ids': [64, 50256], 'len': 2}\n",
      "  14 {'ids': [220, 50256], 'len': 2}\n",
      "t 15 {'ids': [83, 50256], 'len': 2}\n",
      "o 16 {'ids': [78, 50256], 'len': 2}\n",
      "p 17 {'ids': [79, 50256], 'len': 2}\n",
      "  18 {'ids': [220, 50256], 'len': 2}\n",
      "t 19 {'ids': [83, 50256], 'len': 2}\n",
      "i 20 {'ids': [72, 50256], 'len': 2}\n",
      "e 21 {'ids': [68, 50256], 'len': 2}\n",
      "r 22 {'ids': [81, 50256], 'len': 2}\n",
      "  23 {'ids': [220, 50256], 'len': 2}\n",
      "c 24 {'ids': [66, 50256], 'len': 2}\n",
      "e 25 {'ids': [68, 50256], 'len': 2}\n",
      "l 26 {'ids': [75, 50256], 'len': 2}\n",
      "l 27 {'ids': [75, 50256], 'len': 2}\n",
      "i 28 {'ids': [72, 50256], 'len': 2}\n",
      "s 29 {'ids': [82, 50256], 'len': 2}\n",
      "t 30 {'ids': [83, 50256], 'len': 2}\n",
      "  31 {'ids': [220, 50256], 'len': 2}\n",
      "w 32 {'ids': [86, 50256], 'len': 2}\n",
      "i 33 {'ids': [72, 50256], 'len': 2}\n",
      "t 34 {'ids': [83, 50256], 'len': 2}\n",
      "h 35 {'ids': [71, 50256], 'len': 2}\n",
      "o 36 {'ids': [78, 50256], 'len': 2}\n",
      "u 37 {'ids': [84, 50256], 'len': 2}\n",
      "t 38 {'ids': [83, 50256], 'len': 2}\n",
      "  39 {'ids': [220, 50256], 'len': 2}\n",
      "s 40 {'ids': [82, 50256], 'len': 2}\n",
      "t 41 {'ids': [83, 50256], 'len': 2}\n",
      "u 42 {'ids': [84, 50256], 'len': 2}\n",
      "d 43 {'ids': [67, 50256], 'len': 2}\n",
      "y 44 {'ids': [88, 50256], 'len': 2}\n",
      "i 45 {'ids': [72, 50256], 'len': 2}\n",
      "n 46 {'ids': [77, 50256], 'len': 2}\n",
      "g 47 {'ids': [70, 50256], 'len': 2}\n",
      "  48 {'ids': [220, 50256], 'len': 2}\n",
      "a 49 {'ids': [64, 50256], 'len': 2}\n",
      "t 50 {'ids': [83, 50256], 'len': 2}\n",
      "  51 {'ids': [220, 50256], 'len': 2}\n",
      "a 52 {'ids': [64, 50256], 'len': 2}\n",
      "  53 {'ids': [220, 50256], 'len': 2}\n",
      "m 54 {'ids': [76, 50256], 'len': 2}\n",
      "u 55 {'ids': [84, 50256], 'len': 2}\n",
      "s 56 {'ids': [82, 50256], 'len': 2}\n",
      "i 57 {'ids': [72, 50256], 'len': 2}\n",
      "c 58 {'ids': [66, 50256], 'len': 2}\n",
      "  59 {'ids': [220, 50256], 'len': 2}\n",
      "s 60 {'ids': [82, 50256], 'len': 2}\n",
      "c 61 {'ids': [66, 50256], 'len': 2}\n",
      "h 62 {'ids': [71, 50256], 'len': 2}\n",
      "o 63 {'ids': [78, 50256], 'len': 2}\n",
      "o 64 {'ids': [78, 50256], 'len': 2}\n",
      "l 65 {'ids': [75, 50256], 'len': 2}\n",
      "? 66 {'ids': [30, 50256], 'len': 2}\n",
      "\n",
      " 67 {'ids': [198, 50256], 'len': 2}\n",
      "\n",
      " 68 {'ids': [198, 50256], 'len': 2}\n",
      "T 69 {'ids': [51, 50256], 'len': 2}\n",
      "h 70 {'ids': [71, 50256], 'len': 2}\n",
      "e 71 {'ids': [68, 50256], 'len': 2}\n",
      "  72 {'ids': [220, 50256], 'len': 2}\n",
      "o 73 {'ids': [78, 50256], 'len': 2}\n",
      "n 74 {'ids': [77, 50256], 'len': 2}\n",
      "l 75 {'ids': [75, 50256], 'len': 2}\n",
      "y 76 {'ids': [88, 50256], 'len': 2}\n",
      "  77 {'ids': [220, 50256], 'len': 2}\n",
      "t 78 {'ids': [83, 50256], 'len': 2}\n",
      "h 79 {'ids': [71, 50256], 'len': 2}\n",
      "i 80 {'ids': [72, 50256], 'len': 2}\n",
      "n 81 {'ids': [77, 50256], 'len': 2}\n",
      "g 82 {'ids': [70, 50256], 'len': 2}\n",
      "  83 {'ids': [220, 50256], 'len': 2}\n",
      "y 84 {'ids': [88, 50256], 'len': 2}\n",
      "o 85 {'ids': [78, 50256], 'len': 2}\n",
      "u 86 {'ids': [84, 50256], 'len': 2}\n",
      "  87 {'ids': [220, 50256], 'len': 2}\n",
      "n 88 {'ids': [77, 50256], 'len': 2}\n",
      "e 89 {'ids': [68, 50256], 'len': 2}\n",
      "e 90 {'ids': [68, 50256], 'len': 2}\n",
      "d 91 {'ids': [67, 50256], 'len': 2}\n",
      "  92 {'ids': [220, 50256], 'len': 2}\n",
      "t 93 {'ids': [83, 50256], 'len': 2}\n",
      "o 94 {'ids': [78, 50256], 'len': 2}\n",
      "  95 {'ids': [220, 50256], 'len': 2}\n",
      "d 96 {'ids': [67, 50256], 'len': 2}\n",
      "o 97 {'ids': [78, 50256], 'len': 2}\n",
      "  98 {'ids': [220, 50256], 'len': 2}\n",
      "b 99 {'ids': [65, 50256], 'len': 2}\n",
      "e 100 {'ids': [68, 50256], 'len': 2}\n",
      "f 101 {'ids': [69, 50256], 'len': 2}\n",
      "o 102 {'ids': [78, 50256], 'len': 2}\n",
      "r 103 {'ids': [81, 50256], 'len': 2}\n",
      "e 104 {'ids': [68, 50256], 'len': 2}\n",
      "  105 {'ids': [220, 50256], 'len': 2}\n",
      "a 106 {'ids': [64, 50256], 'len': 2}\n",
      "p 107 {'ids': [79, 50256], 'len': 2}\n",
      "p 108 {'ids': [79, 50256], 'len': 2}\n",
      "l 109 {'ids': [75, 50256], 'len': 2}\n",
      "y 110 {'ids': [88, 50256], 'len': 2}\n",
      "i 111 {'ids': [72, 50256], 'len': 2}\n",
      "n 112 {'ids': [77, 50256], 'len': 2}\n",
      "g 113 {'ids': [70, 50256], 'len': 2}\n",
      "  114 {'ids': [220, 50256], 'len': 2}\n",
      "f 115 {'ids': [69, 50256], 'len': 2}\n",
      "o 116 {'ids': [78, 50256], 'len': 2}\n",
      "r 117 {'ids': [81, 50256], 'len': 2}\n",
      "  118 {'ids': [220, 50256], 'len': 2}\n",
      "a 119 {'ids': [64, 50256], 'len': 2}\n",
      "  120 {'ids': [220, 50256], 'len': 2}\n",
      "c 121 {'ids': [66, 50256], 'len': 2}\n",
      "e 122 {'ids': [68, 50256], 'len': 2}\n",
      "l 123 {'ids': [75, 50256], 'len': 2}\n",
      "l 124 {'ids': [75, 50256], 'len': 2}\n",
      "o 125 {'ids': [78, 50256], 'len': 2}\n",
      "  126 {'ids': [220, 50256], 'len': 2}\n",
      "d 127 {'ids': [67, 50256], 'len': 2}\n",
      "e 128 {'ids': [68, 50256], 'len': 2}\n",
      "g 129 {'ids': [70, 50256], 'len': 2}\n",
      "r 130 {'ids': [81, 50256], 'len': 2}\n",
      "e 131 {'ids': [68, 50256], 'len': 2}\n",
      "e 132 {'ids': [68, 50256], 'len': 2}\n",
      "  133 {'ids': [220, 50256], 'len': 2}\n",
      "i 134 {'ids': [72, 50256], 'len': 2}\n",
      "s 135 {'ids': [82, 50256], 'len': 2}\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(tokenized):\n",
    "    print(query[\"text\"][i],i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0e659-e289-43ba-9ae2-a24b852fa794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
